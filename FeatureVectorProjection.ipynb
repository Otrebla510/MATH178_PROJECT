{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the functions we will use are in the file FeatureExtraction.py, which we import here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run FeatureExtraction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also import a library for displaying images, and another for manifold learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "import sklearn.cluster as cl\n",
    "from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a file for each user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = 14 #Sample size\n",
    "directory = 'NewData'\n",
    "\n",
    "make_directory(directory))\n",
    "\n",
    "user_sample = random.sample(get_user_ids(), users)\n",
    "\n",
    "for user_id in user_sample:\n",
    "    print(user_id)\n",
    "    frames = []\n",
    "    for session in get_user_session_ids(user_id):\n",
    "        print(session)\n",
    "        try:\n",
    "            frames.append(get_feature_vector(user_id, session))\n",
    "        except:\n",
    "            print(\"Error in session \" + session)\n",
    "            continue\n",
    "    features = pd.concat(frames, ignore_index = True)\n",
    "    features.to_csv(directory + '/' + user_id + '.csv', header = True, index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then collect all of the different user's data into a single file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect all the files we have in our directory to make our sample\n",
    "listOfFiles = os.listdir(directory)\n",
    "listOfFiles = list(filter(lambda x: len(x) == 10 and x[-4:] == '.csv', listOfFiles))\n",
    "user_sample = list(map(lambda x: x[0:6], listOfFiles))\n",
    "\n",
    "\n",
    "file_name = 'SampleOfUserFeatureVectors.csv'\n",
    "\n",
    "user_data = [pd.read_csv(directory + '/' + user_id + '.csv', header=0, index_col=False) for user_id in user_sample]\n",
    "aggregate_data = pd.concat(user_data, ignore_index = True)\n",
    "aggregate_data['TaskName'] = aggregate_data['SessionID'].map(lambda x: dictio[x])\n",
    "aggregate_data.to_csv(directory + '/' + file_name, header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this code to do manifold learning on a set of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's retrieve the file from the last session\n",
    "directory = 'NewData'\n",
    "file_name = 'SampleOfUserFeatureVectors.csv'\n",
    "data = pd.read_csv(directory + '/' + file_name, header=0, index_col=False)\n",
    "\n",
    "\n",
    "print(\"Data read\")    \n",
    "\n",
    "count_matrix = data.UserID.value_counts()\n",
    "users = count_matrix.index\n",
    "counts = [count_matrix[u] for u in users]\n",
    "bad_users = []\n",
    "for i in range(len(counts)):\n",
    "    if counts[i] < 100:\n",
    "        bad_users.append(users[i])   \n",
    "for b in bad_users:\n",
    "    data = data[data.UserID != b]\n",
    "\n",
    "# Natural log some of them columns\n",
    "for file_name in file_names:\n",
    "    for y in y_columns[file_name]:\n",
    "        for suffix in ['_restoration_time', '_normalized_duration', '_normalized_duration_max']:\n",
    "            data[y + suffix] = log_column(data, y + suffix)\n",
    "\n",
    "data = data.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "print(\"Data processed\")\n",
    "\n",
    "# We're going to try looking at isolating just ONE of a specific feature:\n",
    "feature = 'UserID'\n",
    "random_value = random.choice(data[feature].value_counts().index)\n",
    "data = data[data[feature] == random_value]\n",
    "\n",
    "\n",
    "numeric_data = data[get_numerical_feature_names()]\n",
    "\n",
    "numeric_data_training_sample = numeric_data #numeric_data.sample(n = numeric_data.shape[0] // 10, axis = 0)\n",
    "print(\"Data sampled\")\n",
    "\n",
    "isomap = Isomap(n_neighbors=5, n_components=3)\n",
    "isomap.fit(numeric_data_training_sample)\n",
    "print(\"Fit created\")\n",
    "\n",
    "data_testing_sample = data #data.sample(n = data.shape[0] // 10, axis = 0)\n",
    "numeric_data_testing_sample = data_testing_sample[get_numerical_feature_names()]\n",
    "\n",
    "manifold_3Da = isomap.transform(numeric_data_testing_sample)\n",
    "print(\"Data transformed\")\n",
    "manifold_3D = pd.DataFrame(manifold_3Da, columns=['Comp1', 'Comp2', 'Comp3'])\n",
    "manifold_3D['TapType'] = pd.factorize(data_testing_sample['TapType'])[0]\n",
    "manifold_3D['TaskName'] = pd.factorize(data_testing_sample['TaskName'])[0]\n",
    "manifold_3D['UserID'] = pd.factorize(data_testing_sample['UserID'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_manifold(data: DataFrame, color = None):\n",
    "    \"\"\"\n",
    "    Assume data has the correct columns\n",
    "    \"\"\"\n",
    "    x, y, z = [data[column_name] for column_name in ['Comp1', 'Comp2', 'Comp3']]\n",
    "    ax = plt.figure().gca(projection='3d')\n",
    "    if color != None:\n",
    "        ax.scatter(x, y, z, c=data[color])\n",
    "        plt.title('Color determined by ' + color)\n",
    "    else:\n",
    "        ax.scatter(x, y, z)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_possible_sublists(elements, length):\n",
    "    \"\"\"\n",
    "    All possible sublists of elements having the specified length and preserving order.\n",
    "    This should really use dynamic programming, but it uses recursion instead, so don't\n",
    "    run it on large lists with large values of length\n",
    "    \"\"\"\n",
    "    if length == 0:\n",
    "        return [[]]\n",
    "    sublists = []\n",
    "    for i in range(len(elements)):\n",
    "        remaining_elements = elements[i+1:]\n",
    "        smaller_lists = all_possible_sublists(remaining_elements, length - 1)\n",
    "        append_to_start = lambda x: [elements[i]] + x\n",
    "        sublists += list(map(append_to_start, smaller_lists))\n",
    "    return sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_manifold(manifold_3D, color = None)\n",
    "plot_manifold(manifold_3D, color = 'UserID')\n",
    "plot_manifold(manifold_3D, color = 'TaskName')\n",
    "plot_manifold(manifold_3D, color = 'TapType')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we select two users at random, and use $k=2$ clustering to try to separate them by user. Could also try for TapType, TaskName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'UserID'\n",
    "pair = random.sample(range(len(manifold_3D[feature].value_counts().index)), 2)\n",
    "\n",
    "\n",
    "user_ids = []\n",
    "for user_label in pair:\n",
    "    i = list(manifold_3D[feature].value_counts().index).index(user_label)\n",
    "    user_ids.append(data[feature].value_counts().index[i])\n",
    "print(feature,user_ids[0],'and',feature,user_ids[1])\n",
    "\n",
    "m = manifold_3D[(manifold_3D[feature] == pair[0]) | (manifold_3D[feature] == pair[1])]\n",
    "kmeans = cl.KMeans(n_clusters=2).fit(m[['Comp1', 'Comp2', 'Comp3']])\n",
    "m['Label'] = kmeans.labels_ + 1\n",
    "m[feature] = pd.factorize(m[feature])[0] + 1\n",
    "plot_manifold(m, color = 'Label')\n",
    "plot_manifold(m, color = feature)\n",
    "m['Mix'] = 10 * m['Label'] + m[feature]\n",
    "\n",
    "max_sum = 0\n",
    "for a in [[11,22],[12,21]]:\n",
    "    sum = len(m[(m.Mix == a[0]) | (m.Mix == a[1])])\n",
    "    if sum > max_sum:\n",
    "        max_sum = sum\n",
    "    \n",
    "accuracy = max_sum / len(m)\n",
    "print(\"Frequency of most common label:\", max(m[feature].value_counts()[1], m[feature].value_counts()[2]) / len(m))\n",
    "print(\"Success rate from guessing\",feature,\"by cluster:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the above for all possible pairs of 2 users, and write a histogram to show how well we did in total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature = 'UserID'\n",
    "accuracies = []\n",
    "for pair in all_possible_sublists(range(len(manifold_3D[feature].value_counts().index)), 2):\n",
    "    \n",
    "    user_ids = []\n",
    "    for user_label in pair:\n",
    "        i = list(manifold_3D[feature].value_counts().index).index(user_label)\n",
    "        user_ids.append(data[feature].value_counts().index[i])\n",
    "    print(feature,user_ids[0],'and',feature,user_ids[1])\n",
    "    \n",
    "    values = []\n",
    "    for user_label in pair:\n",
    "        i = list(manifold_3D[feature].value_counts().index).index(user_label)\n",
    "        values.append(data[feature].value_counts().index[i])\n",
    "        \n",
    "    m = manifold_3D[(manifold_3D[feature] == pair[0]) | (manifold_3D[feature] == pair[1])]\n",
    "    kmeans = cl.KMeans(n_clusters=2).fit(m[['Comp1', 'Comp2', 'Comp3']])\n",
    "    m['Label'] = kmeans.labels_ + 1\n",
    "    m[feature] = pd.factorize(m[feature])[0] + 1\n",
    "    m['Mix'] = 10 * m['Label'] + m[feature]\n",
    "\n",
    "    max_sum = 0\n",
    "    for a in [[11,22],[12,21]]: #[[11, 22, 33],[11, 23, 32],[12, 21, 33],[12, 23, 31],[13, 21, 32],[13, 22, 31]]:\n",
    "        sum = len(m[(m.Mix == a[0]) | (m.Mix == a[1])])\n",
    "        if sum > max_sum:\n",
    "            max_sum = sum\n",
    "    \n",
    "    accuracies.append(max_sum / len(m))\n",
    "    print(max(m[feature].value_counts()[1], m[feature].value_counts()[2]) / len(m), max_sum / len(m))\n",
    "    \n",
    "m = mean(accuracies)\n",
    "s = sd(accuracies)\n",
    "print(m)\n",
    "print(s)\n",
    "n, bins, patches = plt.hist(x=accuracies, bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Accuracies of ' + feature + ' prediction by KMeans clustering')\n",
    "maxfreq = n.max()\n",
    "plt.xlim(xmin=0, xmax=1)\n",
    "plt.ylim(ymax=maxfreq + 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we hold the state of motion (or 'gesture scenario', meaning sitting or walking) fixed, and try to compare different activities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gesture_dict = {'Map+Sitting': 0,\n",
    "                'Map+Walking': 1,\n",
    "                'Reading+Sitting': 0,\n",
    "                'Reading+Walking': 1,\n",
    "                'Writing+Sitting': 0,\n",
    "                'Writing+Walking': 1}\n",
    "\n",
    "gesture_labels = ['Sitting', 'Walking']\n",
    "\n",
    "relabel = pd.factorize(data_testing_sample['TaskName'])[1]\n",
    "\n",
    "manifold_3D['GestureScenario'] = manifold_3D['TaskName'].map(lambda x : gesture_dict[relabel[x]])\n",
    "\n",
    "activity_dict = {'Map+Sitting': 0,\n",
    "                'Map+Walking': 0,\n",
    "                'Reading+Sitting': 1,\n",
    "                'Reading+Walking': 1,\n",
    "                'Writing+Sitting': 2,\n",
    "                'Writing+Walking': 2}\n",
    "\n",
    "activity_labels = ['Map', 'Reading', 'Writing']\n",
    "\n",
    "manifold_3D['Activity'] = manifold_3D['TaskName'].map(lambda x : activity_dict[relabel[x]])\n",
    "\n",
    "\n",
    "feature = 'Activity'\n",
    "\n",
    "for i in range(len(gesture_labels)):\n",
    "    \n",
    "    mani = manifold_3D[manifold_3D['GestureScenario'] == i]\n",
    "    \n",
    "    for pair in all_possible_sublists(range(len(mani[feature].value_counts().index)), 2):\n",
    "        print(gesture_labels[i])\n",
    "        print(feature,activity_labels[pair[0]],'and',feature,activity_labels[pair[1]])\n",
    "\n",
    "        m = mani[(mani[feature] == pair[0]) | (mani[feature] == pair[1])] #| (m[feature] == pair[2])]\n",
    "        kmeans = cl.KMeans(n_clusters=2).fit(m[['Comp1', 'Comp2', 'Comp3']])\n",
    "        m['Label'] = kmeans.labels_ + 1\n",
    "        m[feature] = pd.factorize(m[feature])[0] + 1\n",
    "        plot_manifold(m, color = 'Label')\n",
    "        plot_manifold(m, color = feature)\n",
    "        m['Mix'] = 10 * m['Label'] + m[feature]\n",
    "\n",
    "        max_sum = 0\n",
    "        for a in [[11,22],[12,21]]:\n",
    "            sum = len(m[(m.Mix == a[0]) | (m.Mix == a[1])]) # | (m.Mix == a[2])])\n",
    "            if sum > max_sum:\n",
    "                max_sum = sum\n",
    "\n",
    "        accuracy = max_sum / len(m)\n",
    "        print(\"Frequency of most common label:\", \\\n",
    "              max(m[feature].value_counts()[1], m[feature].value_counts()[2]) / len(m))\n",
    "        print(\"Success rate from guessing\",feature,\"by cluster:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
